# Der var engang... - et lille indblik i RegEx og HC Andersen

Online RegEx tester: https://regex101.com/ er en helt fantastisk hjælpsom side til at lære at anvende regulære udtryk (Regex).

W3schools har også en meget brugbar side, der handler om RegEx. https://www.w3schools.com/python/python_regex.asp

Regex' anvendelse er meget udbredt, fordi RegEx er super smart i relation til tekstbehandling, fordi det kan bruges til at foretage avancerede søgninger. RegEx anvendes til søgemaskiner og til søg og erstat funktioner. At arbejde med RegEx er afgjort en oplevelse for sig, men når man får indblik i omfanget af opgaver, som kan løses med RegEx, så indser man, at det er et utroligt godt værktøj.

Denne notebook forsøger ikke at lære dig alt om RegEx, men den forsøger at skabe læring om det, og kun et fåtal af mulighederne bliver illustreret nedenfor.

Foruden RegEx indeholder denne notebook mange loops og list comprehensions, så på den måde kan du også få indblik i, hvordan du skriver den slags.

Kildematerialet (dataen) består i 15 HC Andersen eventyr. Dataen kan downloades herfra: https://github.com/KUBDatalab/datasets

## Indlæs filer

Brug 'os' til at rykke til mappen 'hca' og gemme indholdet af mappen i en liste, som vi kalder _filenames_. 


```python
import os

os.chdir('.\\hca')

file_list = os.listdir()         
```


```python
os.getcwd()
```


```python
file_list
```

Vi bruger lister til at gemme flere elementer i en variabel. Vi kan tilgå hvert element ved at skrive navnet på variablen efterfulgt af to firkantede parenteser, hvor i vi skriver et tal, der henviser til elementets plads i listen. I python er det første element 0 og ikke 1.

For eksempel `file_names[0]` returner '1835_den_lille_idas_blomster.txt', og `file_names[1]` returner '1835_den_uartige_dreng.txt'.

Vi kan også returnere et udsnit af elementer fra listen ved bruge et kolon i den firkantede parentes.

For eksempel `ile_names[0:3]` returner de tre første elementer, og vi vil få samme resultat, hvis vi skriver `file_names[:3]`

Vi kan også benytte negative tal.

For eksempel `file_names[-3:]` returner de tre sidste elementer.

# Indlæs tekster 

Når man åbner en tekst bruger man open(). Man tilføjer et _r_, så python kan regne ud at du åbner filen for at læse den, og man tilføjer encoding for at konvertere data til et læsbart format.

I anden linje skriver vi et ny variabelnavn efterfulgt af forrige variabelnavn og .read() til 



```python
open_file = open(file_list[0], 'r', encoding='utf-8-sig')
raw_text = open_file.read()
open_file.close()
```

Ovenfor har vi åbnet en tekst og gemt den i en variabel, men vi skal åbne 15 tekster. I stedet for at skrive 45 linjer med kode for at gøre dette, så bygger vi et loop, som kan gøre det i seks linjer, og som udnytter at vi kan gemme flere værdier i en liste.

Vi genbruger koden, som vi lige har skrevet og modificerer den en smule.


```python
raw_texts = []
for item in file_list:
    open_file = open(item, 'r', encoding='utf-8-sig')
    raw_text = open_file.read()
    open_file.close()
    raw_texts.append(raw_text)    
```


```python
raw_texts[2]
```

# Clean text

Rensning af tekst kan foregå på flere måder. Metoden nedenfor er på den måde en ud af flere måder.

Vi begynder med at importere RegEx (import re).

RegEx mønsteret er '\b\S+\b'.

\b : \b finder positionen ved grænsen af et ord (word boundary).

\S: \S matcher ethvert ikke-mellemrum

+: + matcher det forrige tegn mellem én og et ubegrænset antal gange, så mange gange som muligt ind til næste tegn. Man siger, at plusset er grådigt.


\b : \b finder positionen ved grænsen af et ord (word boundary).


```python
import re
```


```python
clean_texts = []
for text in raw_texts:
    text_lower_string = text.lower()
    # RexEx funktionen .findall returnerer en liste af ord
    text_clean_list = re.findall(r'\b\S+\b', text_lower_string)
    # Med ' '.join samles ordlisten til en tekststreng
    string_text = ' '.join(text_clean_list)
    # Med append tilføjes tekststrengen til listen clean_texts
    clean_texts.append(string_text) 
```


```python
# listen består af 15 tekster
len(clean_texts)
```


```python
# Første rensede tekst
clean_texts[0]
```

# Sammenligninger

På i dansk litteratur anvender man ofte sammenligninger til at illustrere pointer tydeligere ved at sætte billeder på det man vil beskrive. Sammenligninger bidrager også til at gøre teksten mere levende og intererssant.

Men regex bliver det en overkommelig opgave at hente eksempler på HC Andersens brug af sammenligninger, fordi vi kan finde tekststrenge som følger mønsteret i en typisk sammenligning. 

Vi kan illustrere det på følgende måde. Vi leder efter fraser, hvis mønster enten er _som en ..._ eller _som et ..._.

RegEx mønsteret kan skrives således: 

'som\sen\s\w+|som\set\s\w+'

Ordet _som_ efterfølges af _\s_, der betyder _white space_, der efterfølges af _en_, derefterføgles af _\s_, der efterfølges \w, der betyder _word charater_, der efterfølges af _+_ der betyder "en eller flere af den forrige".

Den lodrette streg, _|_ , betyder eller, som efterfølges af et mønster der stort set er en gentagelse af det mønsteret til venstre for stregen bortset fra, at ordet _en_ er blevet erstattet med ordet _et_. 


```python
comparisons = []
for text in clean_texts:
    comparison = re.findall(r'som\sen\s\w+|som\set\s\w+', text)
    comparisons.append(comparison)
```

RegEx mønsteret kan også skrives således:

'som\se[nt]\s\w+'

Det er: som, mellemrum, e efterfulgt af enten n eller t, mellemrum, ordtegn og flere af dem.


```python
comparisons1 = []
for text in clean_texts:
    comparison = re.findall(r'som\se[nt]\s\w+', text)
    comparisons1.append(comparison)
```

.findall() funktionen tager to obligatoriske argumenter (mønster, text) og et valgfrit ( IGNORECASE - ignorer om det store eller små bogstaver). Bruger vi IGNORECASE fungerer mønsteret vel også på de rå ikke-rensede tekster.


```python
comparisons2 = []
flags = re.IGNORECASE
for text in raw_texts:
    comparison = re.findall(r'som\se[nt]\s\w+', text, flags)
    comparisons2.append(comparison)
```

Der er tomme lister i den liste, som vi får returneret, hvilket viser, der er nogle eventyr, hvor HC Andersen ikke bruger 'som en' eller 'som et'. Det er f.eks. det første eventyr.

Det undrer mig, at HC Andersen ikke bruger sammenligninger i den første tekst, så jeg vil gerne undersøge, hvordan han så bruger 'som'.

Derfor laver jeg mønsteret som mellemrum flere ordtegn mellemrum flere ordtegn og søger med dette mønster i første tekst.


```python
re.findall(r'\w+\ssom\s\w+\s\w+\s\w+', clean_texts[0])
```

Han bruger 'som' og han bruger også sammenligninger, men han bruger ikke 'som en' eller 'som et'.

Resultatet med de tomme lister kan vi 'smukkesere' lidt.

Det kan vi bruge et loop til, men loops kan også skrives, som list comprehensions, hvilket nogle gange er en hurtigere og en smartere metode at bruge. 

I listen ovenfor er der en del tomme felter, og eftersom det ikke ser så smart ud, så vil vi helst sortere dem væk. Det gør vi med en list comprehension, hvori vi også indsætter en betingelse.   


```python
comparisons = [i for i in comparisons if i !=[]]
```

Resultatet er bedre, men stadigvæk ikke helt godt nok. Måske ville det faktisk være bedre, hvis resultatet er helt fald liste.

Vi skriver derfor en list comprehension, der kan flade listen ud.


```python
comparisons = [x for y in comparisons for x in y]
```

Det er en utrolig lang liste, hvor i hvert fald tekststrengen 'som en lille' optræder mere end en gang.

Det ville være smart med en ny mængde, der ikke indeholder dubletter. Det kan vi gøre ved at lave listen om til et _set_, fordi i et _set_ kan man ikke have dubletter.


```python
comparisons = set(comparisons)
```

# Find et tekstuddrag baseret på søgeord og et interval 

Vi vil finde ordet 'sol' samt ord, der er beslægtet med ordet, og vi må have noget kontekst med, fordi vi er faktisk interesseret i at pege ned i teksten og se, hvordan HC Andersen helt præcist bruger ordet sol.

Til dette skal vi bruge _\w._, fordi det giver os flere ordtegn og _{30}_ søger for, at vi får 30 ordtegn før, vi rammer bogstaverne _sol_. _\b_ foran _sol_ søger for at vi kun finder ord, der begynder med _sol_ og ikke ord, hvor _sol_ er en del af ordet, f.eks. tinsoldat. Efter _sol_ søger _\w.{30}_ for, at vi får endnu 30 ordtegn.      


```python
re.findall(r'\w.{30}\bsol\w.{30}', clean_texts[5])
```

Nu får vi et resultat, som ikke er helt efter planen, fordi ordet soldat er vi ikke interesseret i.

Vi forbedrer vores mønster på den måde, at vi tilføjer _[^dig]_ efter _sol_. Den lille hat _^_ inde i de firkantede parenteser søger for at bogstavere _d, i og g_ ikke kan stå på positionen efter _sol_. På den måde slipper vi af med ord som soldat, solid og solgt.


```python
contexts1 = []
for text in clean_texts:
    context = re.findall(r'\w.{30}\bsol[^d]\w.{30}', text) # ig 
    contexts1.append(context)
    
# print ikke lister der er tomme
contexts1 = [i for i in contexts1 if i !=[]]
# flad listen ud
contexts1 = [x for y in contexts1 for x in y]

contexts1 = set(contexts1)
```


```python
contexts1
```

# Find ord, der begynder med store bogstaver


```python
upper_case_words = []
for text in raw_texts:
    upper_case_word = re.findall(r'[A-ZÆØÖÄ]\w+', text)
    upper_case_words.append(upper_case_word)
    
    
# print ikke lister der er tomme
upper_case_words = [i for i in upper_case_words if i !=[]]
# flad listen ud
upper_case_words = [x for y in upper_case_words for x in y]
# fjern dubletter
upper_case_words = set(upper_case_words)
```

Mange af disse ord er skrevet med stort, fordi de optræder efter et punktum, og på den måde er de ikke, hvad jeg vil kalde for "ægte" ord med stort.

Hvis man vil bortfiltrere de "uægte" ord fra sin liste, så kan man afsløre dem ved at lave et loop og indsætte en betingelse, der kan tjekke om, ordene skulle være skrevet med småt andre steder i teksterne, fordi hvis de er det, så er de "uægte".

Konkret gør vi det på den måde at vi looper listen med ord med store bogtaver. Hvis ordet, som vi med .lower() manipulere til kun at bestå af småbogstaver, ikke findes skrevet med et lille begyndelsesbogstav i alle teksterne, så tilføjer vi ordet til vores nye liste med ord med stort begyndelsesbogstav.

NB. vi samler alle tekster i listen raw_texts med ' '.join()      


```python
upper_case_words1 = []
for word in upper_case_words:
    if word.lower() not in ' '.join(raw_texts):
        upper_case_words1.append(word)
```

# Find tekstuddrag baseret på to søgeord og et interval

Det sidste eksempel består i at finde tekstuddrag, der er kendetegnet ved at befinde sig mellem to udvalgte ord og ikke er længere end et udvalgt interval.

Det kan f.eks. være relevant, hvis man er interesseret i at identificere tekstuddrag, hvor to vigtige karakterer eller begreber optræder i nærheden af hinanden.   


```python
contexts2 = []
for text in clean_texts:
    context = re.findall(r'\bsoldat.+?\bprindsesse\w+|\bprindsesse.+?\bsoldat\w+', text) # 
    contexts2.append(context)
    
# print ikke lister der er tomme
contexts2 = [i for i in contexts2 if i !=[]]
# flad listen ud
contexts2 = [x for y in contexts2 for x in y]
# indsæt et max interval mellem første og andet ord 
contexts_within_interval = [item for item in contexts2 if len(item) <= 500]
```

# Hvorfor sker der aldrig noget på en tirsdag? 

Find ord med særlige endelser, f.eks. _dag_, kan være en hjælp til at få indblik i, hvor og hvornår litteraturen foregår.

Man kan også bruge endelserne til at finde grammatiske former, f.eks. vil ord med lang tillægsform være relativt lette at identificere.  


```python
words_endings = []
for w in clean_texts:
    ending = re.findall(r'\w+dag\b', w)
    words_endings.append(ending)

# print ikke lister der er tomme
words_endings = [i for i in words_endings if i !=[]]
# flad listen ud
words_endings = [x for y in words_endings for x in y]
# fjern dubletter
words_endings = set(words_endings)
```


```python
words_endings
```
